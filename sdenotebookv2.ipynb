{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Expected Turnout\n",
    "\n",
    "To predict turnout we have a number of different models that we can use. In the cells below you can select a turnout model and tune the parameter for statewide expected turnout. \n",
    "\n",
    "---\n",
    "Our different models are as follows:\n",
    "\n",
    "1. `exp_16` - models precinct level turnout with the same turnout numbers as 2016\n",
    "2. `exp_08` - models precinct level turnout with the same turnout numbers as 2008\n",
    "3. `exp_avg` - models precinct level turnout with the average of the precinct level turnout numbers from 2016 and 2008\n",
    "4. `exp_percent_16` - models precinct level turnout using the percent of statewide vote per precicnt in 2016 and a parameter for statewide turnout (`expected_statewide_turnout`) that can be adjusted.\n",
    "5. `exp_percent_08` - models precinct level turnout using the percent of statewide vote per precicnt in 2008 and a parameter for statewide turnout (`expected_statewide_turnout`) that can be adjusted.\n",
    "6. `exp_percent_avg` - models precinct level turnout using the average of the percents of statewide vote per precicnt in 2016 and 2008, and a parameter for statewide turnout (`expected_statewide_turnout`) that can be adjusted.7.\n",
    "7. `overall_avg` - models precinct level turnout using the average of `exp_16`, `exp_08`, `exp_percent_16`, and `exp_percent_08`.\n",
    "\n",
    "By default `expected_statewide_turnout` is set to 300,000.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_16 (row):\n",
    "    return row['count16']\n",
    "\n",
    "def exp_08 (row):\n",
    "    return row['count08']\n",
    "\n",
    "def exp_avg (row):\n",
    "    return (exp_16(row) + exp_08(row)) / 2\n",
    "\n",
    "def exp_percent_16 (row):\n",
    "    return (row['count16'] / statewide_turnout_16) * expected_statewide_turnout\n",
    "\n",
    "def exp_percent_08 (row):\n",
    "    return (row['count08'] / statewide_turnout_08) * expected_statewide_turnout\n",
    "\n",
    "def exp_percent_avg (row):\n",
    "    return (exp_percent_16(row) + exp_percent_08(row)) / 2\n",
    "\n",
    "def overall_avg (row):\n",
    "    return (exp_16(row) + exp_08(row) + exp_percent_16(row) + exp_percent_08(row)) / 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SET THE TURNOUT MODEL YOU WANT TO USE ###\n",
    "turnout_model = overall_avg\n",
    "\n",
    "### SET THE EXPECTED STATEWIDE TURNOUT IF YOUR MODEL DEPENDS ON IT ###\n",
    "expected_statewide_turnout = 300000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicted Turnout (Based on IDs)\n",
    "\n",
    "To predict the number of caucus goers for different candidates in individual precincts we assigns weights to each ID we have. \n",
    "\n",
    "First, we weigh each ID based on their response to the Caucus Plan survey question. These values can be set in Caucus Plan Weights. We also include a default value for folks with no response to the Caucus Plan survey question.\n",
    "\n",
    "We then also weight IDs based on their strength. For Warren IDs there are two strengths \"committed\" and \"lean.\" All other candidate IDs are set to a single strength weight. These values can be set in Strength Weights\n",
    "\n",
    "Finaly, we assume a flake rate for our weighted sum only for Warren turnout. \n",
    "\n",
    "---\n",
    "### Caucus Plan Weights\n",
    "\n",
    "The following variable names correspond to the different answers to the caucus plan question and their default weights are shown.\n",
    "\n",
    "* `yes_ip`,      Yes - In Person, Default Weight: 0.9\n",
    "* `yes_vc`,     Yes - Virtual Cacucs, Default Weight: 0.9\n",
    "* `maybe_ip`,    Maybe - In Person, Default Weight: 0.6\n",
    "* `not_caucus`,  Not Caucusing, Default Weight: 0.1\n",
    "* `GOP`,         GOP, Default Weight: 0\n",
    "* `default`,      No Survey Question Response, Default Weight: 0.8\n",
    "\n",
    "\n",
    "---\n",
    "### Stength Weights\n",
    "\n",
    "The following variable names correspond to the different strengths for an ID and thier defualt weights are shown.\n",
    "\n",
    "* `committed_id`, Default Weight: 1\n",
    "* `lean_id`, Default Weight: 0.5\n",
    "* `other_candidate_id`, Default Weight: 1.3\n",
    "\n",
    "---\n",
    "### Flake Rate\n",
    "\n",
    "The `flake_rate` variable can be set to the desired flake rate. By defualt it is set to 85%. Note that the variable is set to the percenate of people who _do_ show up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SET THE CAUCUS PLAN WEIGHTS HERE ###\n",
    "yes_ip = 0.9\n",
    "yes_vc = 0.9\n",
    "maybe_ip = 0.6\n",
    "not_caucus = 0.1\n",
    "GOP = 0\n",
    "default = 0.9\n",
    "\n",
    "### SET THE STRENGTH WEIGHTS HERE ###\n",
    "committed_id = 1\n",
    "lean_id = 0.5\n",
    "other_candidate_id = 1.3\n",
    "\n",
    "### SET THE DESIRED FLAKE RATE HERE ###\n",
    "flake_rate = 0.85"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Delegate Districts\n",
    "\n",
    "In calculating 'Distance to Next Delegate' for single delegate precincts we use 50% + 1 as the distance and the viability threshold. This percent (50%) can be changed in a variable.\n",
    "\n",
    "---\n",
    "\n",
    "Set the `single_delegate_percent` varaible to adjust the 50% threshold for single delgate precicnts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SET THE DESIRED VIABILITY WEIGHTS HERE ###\n",
    "viability_percent = 0.7\n",
    "single_delegate_percent = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import civis\n",
    "import json\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORT CIVIS DATA ###\n",
    "\n",
    "# Setup API client\n",
    "client = civis.APIClient()\n",
    "\n",
    "# Import precinct data\n",
    "to_drop = ['clinton_16', 'hubbell_18', 'clinton_hubbell_sum', 'reporting_multiplier','percent_of_statewide_vote']\n",
    "sql = \"SELECT * FROM analytics_ia.precinct_data\"\n",
    "precinct_data = civis.io.read_civis_sql(sql, \"Warren for MA\", use_pandas=True, client=client)\n",
    "precinct_data.drop(to_drop, inplace=True, axis=1)\n",
    "\n",
    "# Import first choice ID data\n",
    "sql = \"select van_precinct_id, survey_response_name, count(*) from analytics_ia.vansync_responses where mrr_all = 1 and survey_question_name = '1st Choice Caucus' group by 1,2\"    \n",
    "first_choice = civis.io.read_civis_sql(sql, \"Warren for MA\", use_pandas=True, client=client)\n",
    "\n",
    "# Import caucus history data \n",
    "sql = \"SELECT van_precinct_id, SUM(case when caucus_attendee_2016 = 1 then 1 else 0 end) count16, SUM(case when caucus_attendee_2008 = 1 then 1 else 0 end) count08 FROM phoenix_caucus_history_ia.person_caucus_attendance ca LEFT JOIN phoenix_ia.person p ON ca.person_id = p.person_id GROUP BY van_precinct_id\"\n",
    "caucus_history = civis.io.read_civis_sql(sql, \"Warren for MA\", use_pandas=True, client=client)\n",
    "\n",
    "# Import Organizer Turfs\n",
    "sql = \"select van_precinct_id, fo_name from vansync_ia.turf\"\n",
    "turfs = civis.io.read_civis_sql(sql, \"Warren for MA\", use_pandas=True, client=client)\n",
    "turfs.set_index('van_precinct_id', inplace=True)\n",
    "\n",
    "# Import Caucus Plan Response\n",
    "sql = \"SELECT choice_1.van_precinct_id, caucus_plan.survey_response_name, choice_1.survey_response_name, count(distinct choice_1.myv_van_id) FROM(SELECT van_precinct_id, person_id, survey_response_name, myv_van_id FROM analytics_ia.vansync_responses WHERE mrr_all = 1 AND survey_question_name = '1st Choice Caucus') choice_1 LEFT JOIN(SELECT van_precinct_id, person_id, survey_response_name FROM analytics_ia.vansync_responses WHERE mrr_all = 1 AND survey_question_name = 'Caucus Plan') caucus_plan ON choice_1.person_ID =  caucus_plan.person_id GROUP BY 1,2,3\"\n",
    "cube_load = civis.io.read_civis_sql(sql, \"Warren for MA\", use_pandas=True, client=client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cube.loc[1593635, ('Yes - In Person', 'Committed Warren')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Format Imported Data ###\n",
    "\n",
    "# Rename columns in precicnt_data dataframe\n",
    "precinct_data.rename(index=str, columns={\"congressional_district\": \"Congressional District\", \n",
    "                                    \"precinct_id\": \"Precinct ID\", \n",
    "                                    \"county\": \"County\",\n",
    "                                    \"precinct_code\": \"Precinct Code\",\n",
    "                                    \"sos_precinct_name\": \"Sec. State Precinct Name\",\n",
    "                                    \"delegates_to_county_conv\": \"Delegates to County Conv\",\n",
    "                                    \"state_delegate_equivalence_sde\": \"State Delegate Equivalence (SDE)\"}, inplace=True)\n",
    "\n",
    "# Set dtype for columns to float\n",
    "cols = first_choice.columns.drop('survey_response_name')\n",
    "first_choice[cols] = first_choice[cols].astype(np.float32)\n",
    "# Pivot on van_precinct_id\n",
    "fc = first_choice.pivot(index='van_precinct_id', columns='survey_response_name', values='count')\n",
    "# Reset dtype for columns to float\n",
    "cols = fc.columns\n",
    "fc[cols] = fc[cols].astype(np.float32)\n",
    "\n",
    "# Pivot cubeeeee\n",
    "cube  = cube_load['survey_response_name'].fillna('No Response')\n",
    "cube = cube_load.pivot_table(index=['van_precinct_id'], columns=['survey_response_name','survey_response_name col2'])\n",
    "cube.columns = cube.columns.droplevel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot cubeeeee\n",
    "cube  = cube_load\n",
    "cube['survey_response_name'].fillna('No Response', inplace=True)\n",
    "cube = cube.pivot_table(index=['van_precinct_id'], columns=['survey_response_name','survey_response_name col2'])\n",
    "cube.columns = cube.columns.droplevel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new dataframe, df, of historical caucus data and precicnt data\n",
    "df = pd.merge(precinct_data, caucus_history, left_on='Precinct ID', right_on='van_precinct_id')\n",
    "# Set the index of the new df\n",
    "df.set_index('Precinct ID', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ADD EXPECTED TURNOUT TO DF ###\n",
    "\n",
    "# First, calculate statewide turnouts for certain models\n",
    "statewide_turnout_16 = caucus_history['count16'].sum()\n",
    "statewide_turnout_08 = caucus_history['count08'].sum()\n",
    "# Then apply selected model to each row\n",
    "df['Expected Turnout'] = df.apply(turnout_model, axis=1)\n",
    "df['Expected Turnout'] = df['Expected Turnout'].apply(lambda row: round(row, 0))\n",
    "# Remove historical caucus data after turnout calculations are complete\n",
    "columns = ['van_precinct_id', 'count16', 'count08']\n",
    "df.drop(columns, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ADD SDE PER PERSON TO DF ###\n",
    "\n",
    "# Calculate SDE per person based on turnout model\n",
    "df['SDE per Person'] = df.apply(lambda row : row['State Delegate Equivalence (SDE)'] / row['Expected Turnout'], axis=1)\n",
    "# Round to 3 digits\n",
    "df['SDE per Person'] = df['SDE per Person'].apply(lambda row: round(row, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ADD VIABILITY THRESHOLD TO DF ###\n",
    "\n",
    "# Function that maps number of county convention delegates to viability formula\n",
    "def viability_threshold(num_del):\n",
    "    if num_del == 0:\n",
    "        return 0.0\n",
    "    elif num_del == 1:\n",
    "        return 0.0\n",
    "    elif num_del == 2:\n",
    "        return 0.25\n",
    "    elif num_del == 3:\n",
    "        return 1 / 6\n",
    "    else:\n",
    "        return 0.15\n",
    "    \n",
    "# Assign viablity thresholds based on the number of County Convention delegates and the turnout model\n",
    "df['Viability Threshold'] = df.apply(lambda row : math.ceil(row['Expected Turnout'] * viability_threshold(row['Delegates to County Conv'])), axis=1).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add COMMITTED AND LEAN WARREN TO DF ###\n",
    "\n",
    "# Merge Committed Warren fc to df\n",
    "df = pd.merge(df, fc[['Committed Warren']], how=\"left\", left_index=True, right_index=True)\n",
    "# Merge Lean Warren fc to df\n",
    "df = pd.merge(df, fc[['Lean Warren']], how=\"left\", left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "#major = pd.merge(fc, cube, how='left', left_index=True, right_index=True)\n",
    "#major[('Yes - Virtual Caucus', 'Marianne Williamson')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cube.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ADD EXPECTED WARREN TUNROUT AND TO DF ###\n",
    "\n",
    "# Calculate Expected Warrent Tunrout\n",
    "df['Expected Warren Turnout'] = df.apply(lambda row: flake_rate * (row['Committed Warren'] * committed_warren_weight) + (row['Lean Warren'] * lean_warren_weight), axis=1)\n",
    "# Round to whole numbers\n",
    "df['Expected Warren Turnout'] = df['Expected Warren Turnout'].apply(lambda row: round(row, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ADD VIABILITY TO DF ###\n",
    "\n",
    "# Add Viability Threshold to fc\n",
    "fc = pd.merge(fc, df[['Viability Threshold']], how='left', left_index=True, right_index=True)\n",
    "# Calculate whether or not EW is viable for each precinct\n",
    "df['Warren Viable'] = df.apply(lambda row: row['Viability Threshold'] <= row['Expected Warren Turnout'] and row['Expected Warren Turnout'] != 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of responses from cube\n",
    "responses = cube.columns.get_level_values(0).unique().to_list()\n",
    "# Get list of candidates from cube\n",
    "to_drop = ['Committed Warren', 'Lean Warren', 'GOP', 'Other Dem', 'Undecided', 'Refused to say']\n",
    "candidates = cube.columns.get_level_values(1).unique().drop(to_drop).to_list()\n",
    "\n",
    "def other_candidate_counts(row):\n",
    "    num_viable = 0\n",
    "    turnout = 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(row):\n",
    "    #for candidate in candidates:\n",
    "    #    calculate candidate viability\n",
    "    #print(\"Name:\")\n",
    "    return 0, row.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "file  = df.apply(test, axis=1, result_type=\"expand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "\n",
    "# Calculate the number of other viable candidates in each precinct\n",
    "to_drop = ['Committed Warren', 'Lean Warren', 'GOP', 'Other Dem', 'Undecided', 'Refused to say', 'Viability Threshold']\n",
    "candidates = fc.columns.drop(to_drop)\n",
    "\n",
    "def get_other_viable (row):\n",
    "    num_viable = 0\n",
    "    for candidate in candidates:\n",
    "        if (row[candidate] >= viability_percent * row['Viability Threshold']) and (row[candidate] != 0):\n",
    "            num_viable += 1\n",
    "    return num_viable\n",
    "\n",
    "fc['Other Viable Candidates'] = fc.apply(get_other_viable, axis=1)\n",
    "\n",
    "# Calculate the total turnout across other viable candidates\n",
    "def get_turnout (row):\n",
    "    ID_turnout = 0\n",
    "    viable_turnout = 0\n",
    "    for candidate in candidates:\n",
    "        ID_turnout += row[candidate]\n",
    "        # If the candidate has IDs above the viablity threshold\n",
    "        if (row[candidate]) >= row['Viability Threshold'] and (row[candidate] != 0):\n",
    "            # Add the number of IDs to the expected ID turnout\n",
    "            viable_turnout += row[candidate]\n",
    "        # If the candidate has IDs above the viability percent \n",
    "        if (row[candidate] >= viability_percent * row['Viability Threshold']) and (row[candidate] != 0):\n",
    "            # Add the viability threhold to the expected turnout\n",
    "            viable_turnout += row['Viability Threshold']\n",
    "    return ID_turnout, viable_turnout\n",
    "\n",
    "# This is the raw turnout based on IDs\n",
    "def get_ID_turnout (row):\n",
    "    x, y = get_turnout (row)\n",
    "    return x\n",
    "\n",
    "# This is the adjusted turnout rounding up if a candidate has more than the viablity percent\n",
    "# This only includes candidates we think will be viable\n",
    "def get_viable_turnout (row):\n",
    "    x, y = get_turnout (row)\n",
    "    return y\n",
    "\n",
    "fc['Partial ID Turnout'] = fc.apply(get_ID_turnout, axis=1)\n",
    "fc['Other Candidates Viable Turnout'] = fc.apply(get_viable_turnout, axis=1)\n",
    "\n",
    "df = pd.merge(df, fc[['Other Viable Candidates']], how='left', left_index=True, right_index=True)\n",
    "df = pd.merge(df, fc[['Other Candidates Viable Turnout']], how='left', left_index=True, right_index=True)\n",
    "\n",
    "# Calculate total ID turnout by adding ID turnout for other candidates to expected warren turnout\n",
    "df = pd.merge(df, fc[['Partial ID Turnout']], how='left', left_index=True, right_index=True)\n",
    "df['Total ID Turnout'] = df.apply(lambda row: row['Partial ID Turnout'] + row['Expected Warren Turnout'], axis=1)\n",
    "df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate expected number of warren delegates based on exprected warren turnout\n",
    "\n",
    "def expected_dels (row):\n",
    "    et = row['Expected Turnout']\n",
    "    ew = row['Expected Warren Turnout']\n",
    "    oc = row['Other Candidates Viable Turnout']\n",
    "    id_turnout = ew + oc\n",
    "    num_del = row['Delegates to County Conv']\n",
    "    \n",
    "    # Return 0 if not viable\n",
    "    if (not row['Warren Viable']):\n",
    "        return 0\n",
    "    \n",
    "    exp_del = num_del * (ew) / max(et, id_turnout)\n",
    "    if (exp_del % 1) >= 0.5:\n",
    "        return math.ceil(exp_del)\n",
    "    else:\n",
    "        return math.floor(exp_del)\n",
    "\n",
    "df['Expected Warren Delegates'] = df.apply(expected_dels, axis=1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_to_viability (row):\n",
    "    et = row['Expected Turnout']\n",
    "    ew = row['Expected Warren Turnout']\n",
    "    oc = row['Other Candidates Viable Turnout']\n",
    "    num_other = row['Other Viable Candidates']\n",
    "    id_turnout = ew + oc\n",
    "    num_del = row['Delegates to County Conv']\n",
    "    \n",
    "    n = row['Expected Warren Delegates'] + 0.5\n",
    "    \n",
    "    # Lee County\n",
    "    if num_del == 0:\n",
    "        return None\n",
    "    # One delegate precinct\n",
    "    if num_del == 1:\n",
    "        return None\n",
    "    # More than one delegate precicnt\n",
    "    else:\n",
    "        return math.ceil(row['Viability Threshold'] - ew)\n",
    "\n",
    "df['Distance to Viability'] = df.apply(distance_to_viability, axis=1)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_to_next_delegate (row):\n",
    "    et = row['Expected Turnout']\n",
    "    ew = row['Expected Warren Turnout']\n",
    "    oc = row['Other Candidates Viable Turnout']\n",
    "    num_other = row['Other Viable Candidates']\n",
    "    id_turnout = ew + oc\n",
    "    num_del = row['Delegates to County Conv']\n",
    "    \n",
    "    n = row['Expected Warren Delegates'] + 0.5\n",
    "    \n",
    "    # Lee County\n",
    "    if num_del == 0:\n",
    "        return None\n",
    "    \n",
    "    # One delegate precinct\n",
    "    elif num_del == 1:\n",
    "        # Distance to 50% + 1 of expected turnout or id_turnout (whichever is higher)\n",
    "        return math.ceil((max(et, id_turnout) * (0.5)) + 1 - ew)\n",
    "    \n",
    "    # More than one delegate precicnt\n",
    "    else:\n",
    "        \n",
    "        # If we are not yet viable return the distance to viability\n",
    "        if (not row['Warren Viable']):\n",
    "            return math.ceil(row['Viability Threshold'] - ew)\n",
    "        \n",
    "        else:\n",
    "        \n",
    "            # When there are more viable candidates than there are delegates\n",
    "            if (num_other + 1 > num_del):\n",
    "                return -1\n",
    "\n",
    "            # Calculate distance to next assuming expected turnout\n",
    "            dist_to_15 = math.ceil(((n * et) - (num_del * ew)) / num_del)\n",
    "\n",
    "            # If the total is still less than or equal to expected turnout\n",
    "            if (id_turnout + dist_to_15 <= et):\n",
    "                return dist_to_15\n",
    "\n",
    "            # Otherwise calculate distance to next with id_turnout\n",
    "            else:\n",
    "                return math.ceil(((n * (ew + oc)) - (num_del * ew)) / (num_del - n))\n",
    "            \n",
    "df['Distance to Next Delegate'] = df.apply(distance_to_next_delegate, axis=1)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns only used for internal calculations\n",
    "df.drop(['Other Candidates Viable Turnout', 'Partial ID Turnout'], inplace=True, axis=1)\n",
    "# Add organizer turfs\n",
    "df = pd.merge(df, turfs[['fo_name']], how='left', left_index=True, right_index=True)\n",
    "# Sort columns\n",
    "df.sort_values(['fo_name', 'Distance to Next Delegate', 'State Delegate Equivalence (SDE)'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate county level sums\n",
    "county_totals = df.groupby(['County']).sum()\n",
    "# Drop unnessecary columns\n",
    "to_drop = ['Congressional District', 'SDE per Person','Warren Viable', 'Other Viable Candidates']\n",
    "county_totals.drop(to_drop, inplace=True, axis=1)\n",
    "# Find county level counts\n",
    "county_totals['Total Precincts']  = df.groupby('County').size()\n",
    "county_totals['Viable Precincts']  = df.groupby('County')['Warren Viable'].apply(lambda x: x[x == True].count())\n",
    "# Find county level means\n",
    "county_means = df.groupby(['County']).mean()\n",
    "# Rename means\n",
    "county_means.rename(index=str, columns={\"Viability Threshold\": \"Mean Viability Threshold\", \n",
    "                                        \"Distance to Next Delegate\": \"Mean Distance to Next Delegate\",}, inplace=True)\n",
    "# Merge means to totals\n",
    "county_totals = pd.merge(county_totals, county_means[[\"Mean Viability Threshold\", \"Mean Distance to Next Delegate\"]], how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Round data\n",
    "df['State Delegate Equivalence (SDE)'] = df['State Delegate Equivalence (SDE)'].apply(lambda row: round(row, 3))\n",
    "\n",
    "county_totals['State Delegate Equivalence (SDE)'] = county_totals['State Delegate Equivalence (SDE)'].apply(lambda row: round(row, 0))\n",
    "county_totals['Mean Viability Threshold'] = county_totals['Mean Viability Threshold'].apply(lambda row: round(row, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "#county_totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.loc[947318]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}